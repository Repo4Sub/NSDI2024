{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some standard imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import scipy.io as scio\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Module, Parameter, init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModulatorNet(nn.Module):\n",
    "    def __init__(self, signal_dimension, basis_function_length, samples_per_symbol):\n",
    "        super(ModulatorNet, self).__init__()\n",
    "        self._signal_dimension = signal_dimension\n",
    "        self._basis_function_length = basis_function_length\n",
    "        self._samples_per_symbol = samples_per_symbol\n",
    "        self._combination_weight = torch.Tensor([[1,0,0,-1],[0,1,1,0]])\n",
    "\n",
    "        # Signal mapper via transposed convolutional layer\n",
    "        self.signal_part = nn.ConvTranspose1d(in_channels=2*self._signal_dimension, \n",
    "                                        out_channels=4, \n",
    "                                        groups=2, \n",
    "                                        kernel_size=self._basis_function_length, \n",
    "                                        stride=self._samples_per_symbol, \n",
    "                                        bias=False)\n",
    "        # self.signal_comb = nn.Linear(in_features=4,out_features=2,bias=False)\n",
    "\n",
    "    def forward(self, symbol_vetor):\n",
    "        # Get components for real and imaginary parts\n",
    "        signal_components = self.signal_part(symbol_vetor)\n",
    "        # Transpose channel <-> length\n",
    "        signal_components_T = torch.transpose(signal_components, dim0=1, dim1=2)\n",
    "        # Combine components\n",
    "        signal_tx = F.linear(input=signal_components_T,weight=self._combination_weight,bias=None)\n",
    "        # signal_tx = self.signal_comb(signal_components_T)\n",
    "        \n",
    "        return signal_tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 1, 64)\n",
      "1\n",
      "torch.Size([128, 2, 64])\n",
      "(128, 285)\n",
      "torch.Size([128, 285, 2])\n"
     ]
    }
   ],
   "source": [
    "# Load Data symbol\n",
    "# Final symbol tensors will have a shape of (Batch, Channel, Length)\n",
    "Symbol_file = scio.loadmat('./TrainingWaveform/QAM/QAMSymbol_batch.mat')\n",
    "Symbol = Symbol_file['QAMSymbol_batch']\n",
    "print(Symbol.shape)\n",
    "# Symbol matrix has a shape of (Batch, Channel, Length)\n",
    "signal_dimension = Symbol.shape[1]\n",
    "print(signal_dimension)\n",
    "# Extract real and imaginary parts to form the input mat\n",
    "Symbol_real = np.real(Symbol)\n",
    "Symbol_imag = np.imag(Symbol)\n",
    "Symbol_mat = np.concatenate((Symbol_real, Symbol_imag), axis = 1).astype('float32')\n",
    "\n",
    "# Add a dimension at 0 for Batch\n",
    "Symbol_tensor = torch.tensor(Symbol_mat)\n",
    "print(Symbol_tensor.shape)\n",
    "\n",
    "# Load Waveform\n",
    "# Final Waveform tensors will have a shape of (Batch, Length, 2)\n",
    "Waveform_file = scio.loadmat('./TrainingWaveform/QAM/QAMSignal_batch.mat')\n",
    "Waveform = Waveform_file['QAMSignal_batch']\n",
    "print(Waveform.shape)\n",
    "# Waveform matrix has a shape of (Batch, Length)\n",
    "# Extract real and imaginary parts to form the input mat\n",
    "Waveform_real = np.real(Waveform)\n",
    "Waveform_imag = np.imag(Waveform)\n",
    "Waveform_mat = np.stack((Waveform_real, Waveform_imag), axis = 2).astype('float32')\n",
    "\n",
    "Waveform_tensor = torch.tensor(Waveform_mat)\n",
    "\n",
    "print(Waveform_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 33])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_156684/3615671927.py:8: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525552411/work/torch/csrc/utils/tensor_numpy.cpp:199.)\n",
      "  basis_imag_tensor = torch.Tensor(np.imag(basis_fucntions)).unsqueeze(dim=1)\n"
     ]
    }
   ],
   "source": [
    "# Configure basis function\n",
    "basis_fucntion_file = scio.loadmat('./TrainingWaveform/QAM/rrc_filter_taps.mat')\n",
    "basis_fucntions = basis_fucntion_file['rrc_filter_taps']\n",
    "# Basis function matrix has a shape of (Dimensions, Length) \n",
    "basis_fucntion_length = basis_fucntions.shape[1]\n",
    "# Extract real and imaginary parts of basis functions\n",
    "basis_real_tensor = torch.Tensor(np.real(basis_fucntions)).unsqueeze(dim=1)\n",
    "basis_imag_tensor = torch.Tensor(np.imag(basis_fucntions)).unsqueeze(dim=1)\n",
    "basis_tensor = torch.concat([basis_real_tensor,basis_imag_tensor],dim=1)\n",
    "basis_tensor = torch.concat([basis_tensor,basis_tensor],dim=0)\n",
    "# Configure samples per symbol\n",
    "samples_per_symbol = 4\n",
    "print(basis_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 285, 2])\n"
     ]
    }
   ],
   "source": [
    "# Use ModulatorNet to generate signal\n",
    "QAM_Modulator = ModulatorNet(signal_dimension=signal_dimension, \n",
    "                        basis_function_length=basis_fucntion_length,\n",
    "                        samples_per_symbol=samples_per_symbol)\n",
    "QAM_Modulator.signal_part.weight.data = basis_tensor\n",
    "QAM_Waveform = QAM_Modulator(Symbol_tensor)\n",
    "print(QAM_Waveform.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to ONNX\n",
    "import torch.onnx\n",
    "QAM_Modulator.eval()\n",
    "InputSymbol = Symbol_tensor\n",
    "OutputWaveform = QAM_Modulator(InputSymbol)\n",
    "torch.onnx.export(QAM_Modulator,InputSymbol,\"QAM_RRC_Modulator.onnx\", export_params=True, \n",
    "                    opset_version=13,input_names = ['inputsymbol'],output_names = ['outputwaveform'],\n",
    "                    dynamic_axes={'inputsymbol' : {0 : 'batch_size', 2: 'symbol_length'},    \n",
    "                                'outputwaveform' : {0 : 'batch_size', 1: 'waveform_length'}})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15 (default, Nov 24 2022, 15:19:38) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "03c210b107f9f4ef3426c39af96db5ef5e1b52b05149c132b7a963dbe198041b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
